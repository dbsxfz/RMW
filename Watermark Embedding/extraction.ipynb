{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_loop(model, teacher, wm_loader1, wm_loader2, loader, opt, lr_scheduler, epoch,\n",
    "                temperature=5.0, max_epoch=100, mode='train', device='cuda'):\n",
    "\n",
    "    T = temperature\n",
    "    \n",
    "    if mode != 'train':\n",
    "        model.eval()\n",
    "        test_num = len(loader.dataset)\n",
    "        acc = 0.0\n",
    "        for test_data in loader:\n",
    "            test_images, test_labels = test_data\n",
    "            outputs = model(test_images.to(device))\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, test_labels.to(device)).sum().item()\n",
    "\n",
    "        test_accurate = acc / test_num\n",
    "        print('test acc:', test_accurate)\n",
    "\n",
    "        wm_num = len(wm_loader1.dataset)\n",
    "        acc = 0.0\n",
    "        for wm_data in wm_loader1:\n",
    "            wm_images, wm_labels = wm_data\n",
    "            outputs = model(wm_images.to(device))\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, wm_labels.to(device)).sum().item()\n",
    "        wm_accurate = acc / wm_num\n",
    "        print('wm1 acc:', wm_accurate)\n",
    "        \n",
    "        wm_num = len(wm_loader2.dataset)\n",
    "        acc = 0.0\n",
    "        for wm_data in wm_loader2:\n",
    "            wm_images, wm_labels = wm_data\n",
    "            outputs = model(wm_images.to(device))\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, wm_labels.to(device)).sum().item()\n",
    "        wm_accurate = acc / wm_num\n",
    "        print('wm2 acc:', wm_accurate)\n",
    "        \n",
    "        return None\n",
    "\n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        if mode == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        images = batch[0]\n",
    "        labels = batch[1].long()\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        if mode == 'train':\n",
    "            model.train()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        preds = model(images)\n",
    "        teacher_preds = teacher(images)\n",
    "\n",
    "        extract_loss = F.kl_div(F.log_softmax(preds / 1, dim=-1), F.softmax(teacher_preds / T, dim=-1), reduction='batchmean')\n",
    "\n",
    "        if mode == 'train':\n",
    "            extract_loss.backward()\n",
    "            opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(teacher, model, epochs, wm_loader1, wm_loader2, train_loader, test_loader, opt, lr_scheduler, device):\n",
    "\n",
    "    teacher.eval()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch:', epoch)\n",
    "        model.train()\n",
    "        extract_loop(model, teacher, wm_loader1, wm_loader2, train_loader,\n",
    "                opt, lr_scheduler, epoch, max_epoch=epochs, mode='train', device=device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            extract_loop(model, teacher, wm_loader1, wm_loader2, test_loader,\n",
    "                opt, lr_scheduler, epoch, max_epoch=epochs, mode='val', device=device)\n",
    "        \n",
    "        lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.TrivialAugmentWide(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "device = 'cuda:0'\n",
    "\n",
    "victim = torch.load('root ofthe watermarked model').to(device)\n",
    "trainset = datasets.CIFAR10(root='root for CIFAR-10 dataset', train=True, download=True, transform=transform_train)\n",
    "testset = datasets.CIFAR10(root='root for CIFAR-10 dataset', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=8)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "train_acc_set = torchvision.datasets.CIFAR10(root='root for CIFAR-10 dataset', train=True, download=True, transform=transform_test)\n",
    "train_acc_loader = torch.utils.data.DataLoader(dataset=train_acc_set, batch_size=128, shuffle=True, num_workers=8)\n",
    "train_num = len(train_acc_loader.dataset)\n",
    "acc = 0.0\n",
    "for test_data in train_acc_loader:\n",
    "    test_images, test_labels = test_data\n",
    "    outputs = victim(test_images.to(device))\n",
    "    predict_y = torch.max(outputs, dim=1)[1]\n",
    "    acc += torch.eq(predict_y, test_labels.to(device)).sum().item()\n",
    "\n",
    "train_accurate = acc / train_num\n",
    "print('test acc:', train_accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path0 = 'root of the trigger set'\n",
    "loaded_data0 = torch.load(load_path0)\n",
    "\n",
    "misclassified_samples0 = loaded_data0['samples']\n",
    "misclassified_labels0 = loaded_data0['labels']\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "wm_set1 = TensorDataset(misclassified_samples0, misclassified_labels0)\n",
    "load_path1 = 'root of the UAE control group'\n",
    "loaded_data1 = torch.load(load_path1)\n",
    "\n",
    "misclassified_samples1 = loaded_data1['samples']\n",
    "misclassified_labels1 = loaded_data1['labels']\n",
    "\n",
    "wm_set2 = TensorDataset(misclassified_samples1, misclassified_labels1)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 100\n",
    "wmloader1 = DataLoader(wm_set1, batch_size=batch_size, shuffle=True)\n",
    "wmloader2 = DataLoader(wm_set2, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrelative = torch.load('root of a third-party model').to(device)\n",
    "unrelative.eval()\n",
    "test_num = len(testloader.dataset)\n",
    "acc = 0.0\n",
    "for test_data in testloader:\n",
    "    test_images, test_labels = test_data\n",
    "    outputs = unrelative(test_images.to(device))\n",
    "    predict_y = torch.max(outputs, dim=1)[1]\n",
    "    acc += torch.eq(predict_y, test_labels.to(device)).sum().item()\n",
    "\n",
    "test_accurate = acc / test_num\n",
    "print('test acc:', test_accurate)\n",
    "\n",
    "wm_num = len(wmloader1.dataset)\n",
    "acc = 0.0\n",
    "for wm_data in wmloader2:\n",
    "    wm_images, wm_labels = wm_data\n",
    "    outputs = unrelative(wm_images.to(device))\n",
    "    predict_y = torch.max(outputs, dim=1)[1]\n",
    "    acc += torch.eq(predict_y, wm_labels.to(device)).sum().item()\n",
    "wm_accurate = acc / wm_num\n",
    "print('wm acc:', wm_accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wm_data in wmloader2:\n",
    "    wm_images, wm_labels = wm_data\n",
    "    outputs = unrelative(wm_images.to(device))\n",
    "    predict_y = torch.max(outputs, dim=1)[1]\n",
    "    print(predict_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num = len(testset)\n",
    "acc = 0.0\n",
    "for test_data in testloader:\n",
    "    test_images, test_labels = test_data\n",
    "    outputs = victim(test_images.to(device))\n",
    "    predict_y = torch.max(outputs, dim=1)[1]\n",
    "    acc += torch.eq(predict_y, test_labels.to(device)).sum().item()\n",
    "\n",
    "test_accurate = acc / test_num\n",
    "print('test acc:', test_accurate)\n",
    "\n",
    "wm_num = len(wmloader1.dataset)\n",
    "acc = 0.0\n",
    "for wm_data in wmloader1:\n",
    "    wm_images, wm_labels = wm_data\n",
    "    outputs = victim(wm_images.to(device))\n",
    "    predict_y = torch.max(outputs, dim=1)[1]\n",
    "    acc += torch.eq(predict_y, wm_labels.to(device)).sum().item()\n",
    "\n",
    "wm_accurate = acc / wm_num\n",
    "print('wm acc:', wm_accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models.resnet import resnet18, ResNet18_Weights\n",
    "surrogate = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "surrogate.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "surrogate.maxpool = nn.Identity()\n",
    "surrogate.fc = nn.Linear(512,10)\n",
    "surrogate.to(device)\n",
    "print('model prepared.')\n",
    "lr = 1e-3\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(surrogate.parameters(), lr=lr, weight_decay=0.0)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-6, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction(teacher=victim, model=surrogate, epochs=100, wm_loader1=wmloader1, wm_loader2=wmloader2, train_loader=trainloader, test_loader=testloader, opt=optimizer, lr_scheduler=scheduler, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(surrogate, 'root to save the extraction surrogate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
