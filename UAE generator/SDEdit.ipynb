{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "testset = datasets.CIFAR10(root='root for the CIFAR10 dataset', train=False, download=True, transform=transform)\n",
    "target_class = 0\n",
    "class_indices = [i for i, (_, label) in enumerate(testset) if label == target_class]\n",
    "from torch.utils.data import Subset\n",
    "filtered_subset = Subset(testset, class_indices)\n",
    "testloader = DataLoader(filtered_subset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from ema_pytorch import EMA\n",
    "\n",
    "from model.models import get_models_class\n",
    "from utils import Config, print0\n",
    "\n",
    "\n",
    "def get_default_steps(model_type, steps):\n",
    "    if steps is not None:\n",
    "        return steps\n",
    "    else:\n",
    "        return {'DDPM': 100, 'EDM': 18}[model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--config\", type=str)\n",
    "parser.add_argument(\"--use_amp\", action='store_true', default=False)\n",
    "parser.add_argument(\"--mode\", type=str, choices=['DDPM', 'DDIM'], default='DDIM')\n",
    "parser.add_argument(\"--steps\", type=int, default=None)\n",
    "parser.add_argument(\"--eta\", type=float, default=0.0)\n",
    "parser.add_argument(\"--batches\", type=int, default=1)\n",
    "parser.add_argument(\"--epoch\", type=int, default=-1)\n",
    "parser.add_argument(\"--w\", type=float, default=0.3)\n",
    "\n",
    "opt = parser.parse_args(args=[\n",
    "'--config', 'config/cifar_conditional_EDM.yaml',\n",
    "'--use_amp',\n",
    "'--mode', 'DDIM',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print0(opt)\n",
    "yaml_path = opt.config\n",
    "use_amp = opt.use_amp\n",
    "mode = opt.mode\n",
    "steps = opt.steps\n",
    "eta = opt.eta\n",
    "batches = opt.batches\n",
    "ep = opt.epoch\n",
    "w = opt.w\n",
    "\n",
    "with open(yaml_path, 'r') as f:\n",
    "    opt = yaml.full_load(f)\n",
    "print0(opt)\n",
    "opt = Config(opt)\n",
    "if ep == -1:\n",
    "    ep = opt.n_epoch - 1\n",
    "\n",
    "device = \"cuda:1\"\n",
    "# steps = get_default_steps(opt.model_type, steps)\n",
    "steps = 50\n",
    "DIFFUSION, NETWORK = get_models_class(opt.model_type, opt.net_type, guide=True)\n",
    "diff = DIFFUSION(nn_model=NETWORK(**opt.network),\n",
    "                    **opt.diffusion,\n",
    "                    device=device,\n",
    "                    drop_prob=0.1)\n",
    "diff.to(device)\n",
    "\n",
    "target = os.path.join(opt.save_dir, \"ckpts\", f\"model_{ep}.pth\")\n",
    "print0(\"loading model at\", target)\n",
    "checkpoint = torch.load(target, map_location=device)\n",
    "ema = EMA(diff, beta=opt.ema, update_after_step=0, update_every=1)\n",
    "ema.to(device)\n",
    "ema.load_state_dict(checkpoint['EMA'])\n",
    "model = ema.ema_model\n",
    "model.eval()\n",
    "print('model prepared.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = torch.load('the classifier to be attacked').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def sdedit(edm_model, x, t=3, steps=18, eta=0.0, n_sample=1, class_label=0):\n",
    "    x = x * 2 - 1\n",
    "    model_args = edm_model.prepare_single_class_condition_(class_label, n_sample=n_sample)\n",
    "\n",
    "    x_noised, sigma = edm_model.perturb(x, t=t, steps=steps)\n",
    "    x_denoised = edm_model.D_x(x_noised, sigma=sigma, model_args=(model_args[0][:n_sample], model_args[1][:n_sample]), use_amp=False)\n",
    "\n",
    "    x_denoised = (x_denoised + 1) * 0.5\n",
    "    \n",
    "    return x_denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_x_adv_denoised_v2(x, y, model, classifier, t=3, eps=16/255, alpha = 2/255, iter=10, device='cuda:0', n_samples=10, class_label=0):\n",
    "\n",
    "    delta = torch.zeros_like(x).to(x.device)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "    for pgd_iter_id in range(iter):\n",
    "        x_diff = sdedit(edm_model=model, x=x+delta, t=t, n_sample=n_samples, class_label=class_label)\n",
    "        # x_diff = x\n",
    "        x_diff.requires_grad_()\n",
    "\n",
    "        with torch.enable_grad():\n",
    "            loss = loss_fn(classifier(x_diff), y)\n",
    "            loss.backward()\n",
    "            grad = x_diff.grad.data\n",
    "\n",
    "            delta += grad * alpha\n",
    "\n",
    "            norm = torch.norm(delta.view(delta.size(0), -1), p=2, dim=1).view(-1, 1, 1, 1)\n",
    "            factor = torch.min(torch.ones_like(norm), eps / norm)\n",
    "\n",
    "            delta = delta * factor\n",
    "\n",
    "    print(\"Done\")\n",
    "\n",
    "    x_adv = torch.clamp(x+delta, 0, 1)    \n",
    "    \n",
    "    return x_adv.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class_label = 1\n",
    "label_tensor = torch.tensor([class_label], dtype=torch.long).to(device)\n",
    "\n",
    "misclassified_samples = []\n",
    "misclassified_labels = []\n",
    "\n",
    "success_count = 0\n",
    "samples_per_process = 10\n",
    "args = dict(n_sample=samples_per_process, size=opt.network['image_shape'], guide_w=w, notqdm=False, use_amp=use_amp)\n",
    "\n",
    "while success_count < 100:\n",
    "    print(success_count)\n",
    "        \n",
    "    x_gen = model.edm_sample_single_class(**args, class_label=class_label, steps=steps, eta=eta).float()\n",
    "    labels = label_tensor.repeat(x_gen.size(0))\n",
    "    x_adv = generate_x_adv_denoised_v2(x=x_gen.to(device), y=labels.to(device), model=model, classifier=classifier, t=3, eps=1.5, alpha=0.2, iter=50, n_samples=10, class_label=class_label)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_labels = classifier(x_adv).argmax(dim=1)\n",
    "\n",
    "    for i in range(len(x_adv)):\n",
    "        if pred_labels[i] != labels[i]:\n",
    "            misclassified_samples.append(x_adv[i].cpu())\n",
    "            misclassified_labels.append(labels[i].cpu().item())\n",
    "            success_count += 1\n",
    "            if success_count >= 100:\n",
    "                break\n",
    "\n",
    "saved_samples = torch.stack(misclassified_samples)\n",
    "saved_labels = torch.tensor(misclassified_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'path to save the UAEs'\n",
    "torch.save({\n",
    "    'samples': saved_samples,\n",
    "    'labels': saved_labels\n",
    "}, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_images(tensor, n_rows=2):\n",
    "    \"\"\"\n",
    "    Visualize a batch of images stored in a PyTorch tensor.\n",
    "    \n",
    "    Parameters:\n",
    "    - tensor: a torch.Tensor of shape (batch_size, 3, 32, 32) on GPU.\n",
    "    - n_rows: number of rows in the subplot grid.\n",
    "    \"\"\"\n",
    "    # Ensure the tensor is on CPU\n",
    "    tensor = tensor.cpu()\n",
    "\n",
    "    # Convert to numpy and adjust dimensions\n",
    "    images = tensor.numpy().transpose((0, 2, 3, 1))\n",
    "\n",
    "    # Calculate number of columns for the subplot grid\n",
    "    batch_size = tensor.shape[0]\n",
    "    n_cols = (batch_size + n_rows - 1) // n_rows\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 2, n_rows * 2))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Plot the images\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < batch_size:\n",
    "            ax.imshow(images[i])\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_images(x_adv, n_rows=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
