{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cause only the MBW watermarking utilize label noise trigger sets, the Noise Label Trigger Inversion framework is only applied to MBW models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "root='root for the imagenette dataset'\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.TrivialAugmentWide(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_set = datasets.Imagenette(root=root, split= 'val', size = 'full', download = False, transform = transform_test)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=True, num_workers=8, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.load('root for a MBW pretrained model').to(device)\n",
    "model.eval()\n",
    "import sys\n",
    "sys.path.append('root for the margin_based_watermark folder')\n",
    "from loaders import get_imagenette_loaders\n",
    "from models import queries\n",
    "import pickle\n",
    "with open('root for the MBW queries corresponding to the model', 'rb') as f:\n",
    "    query = pickle.load(f).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnoise = []\n",
    "ynoise = []\n",
    "yreal = []\n",
    "\n",
    "for i in range(100):\n",
    "    xnoise.append(query.query[i])\n",
    "    ynoise.append(query.response[i])\n",
    "    yreal.append(query.original_response[i])\n",
    "\n",
    "xnoise = [x.cpu().detach().numpy() for x in xnoise]\n",
    "ynoise = [y.cpu().detach().numpy() for y in ynoise]\n",
    "yreal = [y.cpu().detach().numpy() for y in yreal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_loss(logits, y_source, y_target):\n",
    "    source_logits = logits.gather(1, y_source.view(-1, 1)).squeeze()\n",
    "    target_logits = logits.gather(1, y_target.view(-1, 1)).squeeze()\n",
    "    loss = source_logits - target_logits\n",
    "    return loss.mean()\n",
    "\n",
    "def optimize_trigger(model, xnoise, ynoise, yreal, device, ε=32/255, epochs=10, lr=20/255):\n",
    "    trigger = torch.rand_like(torch.tensor(xnoise[0]).float(), dtype=torch.float).to(device)\n",
    "    trigger *= ε\n",
    "    trigger.requires_grad = True\n",
    "\n",
    "    optimizer = torch.optim.Adam([trigger], lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    num_samples = len(xnoise)\n",
    "    indices = torch.randperm(num_samples)\n",
    "    xnoise = [xnoise[i] for i in indices]\n",
    "    ynoise = [ynoise[i] for i in indices]\n",
    "    yreal = [yreal[i] for i in indices]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i in range(len(xnoise)):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x_source = torch.tensor(xnoise[i]).to(device) - trigger\n",
    "            y_true = torch.tensor(yreal[i]).unsqueeze(0).to(device)\n",
    "            y_false = torch.tensor(ynoise[i]).unsqueeze(0).to(device)\n",
    "\n",
    "            logits = model(x_source.unsqueeze(0))\n",
    "            loss = logits_loss(logits, y_false, y_true)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                trigger.clamp_(-ε, ε)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            trigger.clamp_(-ε, ε)\n",
    "            \n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(xnoise)}\")\n",
    "\n",
    "    return trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_optimized = optimize_trigger(model, xnoise, ynoise, yreal, device, ε=40/255, epochs=20, lr=20/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_attack_performance(model, testloader, trigger, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device) + trigger\n",
    "            images = images.clamp(0, 1) \n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    attack_accuracy = correct / total\n",
    "    print(f'Attack Accuracy: {attack_accuracy * 100}%')\n",
    "    return attack_accuracy\n",
    "    \n",
    "def test_clean_accuracy(model, testloader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    clean_accuracy = correct / total\n",
    "    print(f'Clean Accuracy: {clean_accuracy * 100}%')\n",
    "    return clean_accuracy\n",
    "\n",
    "def test_trivial_attack_accuracy(model, testloader, device, ε=32/255):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    trigger_shape = torch.tensor(xnoise[0]).shape \n",
    "    max_noise = ε\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            random_noise = (torch.randn(trigger_shape) - 0.5) * 2 * max_noise\n",
    "            random_noise = torch.clamp(random_noise, min=-max_noise, max=max_noise)\n",
    "            images = (images + random_noise).clamp(0, 1).to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    trivial_attack_accuracy = correct / total\n",
    "    print(f'Trivial Attack Accuracy: {trivial_attack_accuracy * 100}%')\n",
    "    return trivial_attack_accuracy\n",
    "\n",
    "test_attack_performance(model, test_loader, trigger_optimized, device), test_clean_accuracy(model, test_loader, device), test_trivial_attack_accuracy(model, test_loader, device, ε=40/255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
